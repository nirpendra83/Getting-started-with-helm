var relearn_searchindex = [
  {
    "breadcrumb": "Introduction to Helm \u003e Introduction to Helm",
    "content": "📌 Introduction to Helm What is Helm? Why use Helm for Kubernetes application deployment? Key components: Charts, Repositories, Releases 📚 Exploring the Official Helm Documentation Navigating helm.sh/docs Installation and prerequisites Understanding the Helm CLI and commands Helm 3 vs Helm 2 (brief overview) 🧩 Working with Existing Helm Charts 🔍 Discovering and Using Helm Repositories Adding public and private chart repositories Searching for charts (helm search hub vs helm search repo) Repository management commands 🚀 Deploying a Helm Release Installing a chart as a release Setting a namespace for the deployment Dry run and debug before actual deployment ⚙️ Customizing Charts with Values Understanding values.yaml Overriding values using: Custom values.yaml files --set CLI option --set-file and --set-string 🔁 Managing Helm Releases Upgrading a release with updated values or chart versions Rolling back to a previous release version Viewing and diffing historical release versions Uninstalling a release cleanly 🌐 Multi-Environment Helm Usage Structuring values for different environments (dev, staging, prod) Folder-based environment separation Using --values with multiple files for environment-specific configs 🛠️ Creating Your Own Helm Charts ⚡ Helm Chart Quick Start helm create mychart Directory structure explained Modifying the default template 🧬 Helm Template Engine and Syntax How Helm renders templates Using {{ .Values }}, {{ .Chart }}, {{ .Release }} objects 🏗 Built-in Objects and Functions Overview of available Helm objects Useful template functions (include, required, lookup, toYaml, etc.) Best practices in chart templating 🧪 Testing and Validating Charts helm lint and template validation Using helm template for local rendering Unit testing templates with tools like helm-unittest 🧰 Troubleshooting and Tips Debugging with --debug and --dry-run Common errors and how to fix them Checking logs and Helm release history Understanding exit codes and command output",
    "description": "📌 Introduction to Helm What is Helm? Why use Helm for Kubernetes application deployment? Key components: Charts, Repositories, Releases 📚 Exploring the Official Helm Documentation Navigating helm.sh/docs Installation and prerequisites Understanding the Helm CLI and commands Helm 3 vs Helm 2 (brief overview) 🧩 Working with Existing Helm Charts 🔍 Discovering and Using Helm Repositories Adding public and private chart repositories Searching for charts (helm search hub vs helm search repo) Repository management commands 🚀 Deploying a Helm Release Installing a chart as a release Setting a namespace for the deployment Dry run and debug before actual deployment ⚙️ Customizing Charts with Values Understanding values.yaml Overriding values using: Custom values.yaml files --set CLI option --set-file and --set-string 🔁 Managing Helm Releases Upgrading a release with updated values or chart versions Rolling back to a previous release version Viewing and diffing historical release versions Uninstalling a release cleanly 🌐 Multi-Environment Helm Usage Structuring values for different environments (dev, staging, prod) Folder-based environment separation Using --values with multiple files for environment-specific configs 🛠️ Creating Your Own Helm Charts ⚡ Helm Chart Quick Start helm create mychart Directory structure explained Modifying the default template 🧬 Helm Template Engine and Syntax How Helm renders templates Using {{ .Values }}, {{ .Chart }}, {{ .Release }} objects 🏗 Built-in Objects and Functions Overview of available Helm objects Useful template functions (include, required, lookup, toYaml, etc.) Best practices in chart templating 🧪 Testing and Validating Charts helm lint and template validation Using helm template for local rendering Unit testing templates with tools like helm-unittest 🧰 Troubleshooting and Tips Debugging with --debug and --dry-run Common errors and how to fix them Checking logs and Helm release history Understanding exit codes and command output",
    "tags": [],
    "title": "Helm Contents",
    "uri": "/helm/toc/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Deploy a .NET Core Web API using Docker and Kubernetes",
    "content": "Table of Contents Day 01:\nIntroduction to Git and Common Git Commands Overview of Docker, Dockerfile, and Docker Compose Day 02:\nHands-on with Docker Compose Getting Started with Kubernetes Day 03:\nExploring Core Kubernetes Concepts Setting Up Jenkins for Automation Day 04:\nProject Walkthrough: Dockerizing and Deploying the Application on Kubernetes Day 05:\nImplementing a CI/CD Pipeline with Jenkins for Docker and Kubernetes Deployment",
    "description": "A comprehensive guide to building, containerizing, and deploying a .NET Core Web API on Kubernetes using Docker.",
    "tags": [
      "Dotnet",
      "Kubernetes",
      "Docker",
      "Webapi",
      "Devops"
    ],
    "title": "Planning",
    "uri": "/dotnet/planning.md/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Introduction to Helm",
    "content": "📦 Session 1: Introduction to Helm Helm is the package manager for Kubernetes, designed to simplify deployment, configuration, and lifecycle management of Kubernetes applications using reusable packages called charts.\n⚙️ Prerequisites Before using Helm, ensure the following:\n✅ A working Kubernetes cluster ✅ kubectl configured to access the cluster ✅ Helm CLI installed on your local system 🔧 Install Helm curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\r🧩 Verify Helm Installation helm version\r🌐 How Helm Connects to Kubernetes Helm does not need a server component (like Tiller in v2). It uses:\nYour existing kubeconfig file (~/.kube/config) Communicates directly with Kubernetes API server Uses standard Kubernetes resources: Deployments, Services, Secrets, etc. Releases are tracked in your cluster (by default stored as Kubernetes Secrets) In essence, Helm is just another Kubernetes client, like kubectl, but focused on packages.\n🚀 Getting Started: Using Existing Helm Charts The fastest way to start with Helm is by installing applications using public charts.\n1️⃣ Add a Chart Repository helm repo add bitnami https://charts.bitnami.com/bitnami\r2️⃣ Update the Repository Cache helm repo update\r3️⃣ Search for a Chart helm search repo nginx\r4️⃣ Install a Chart helm install my-nginx bitnami/nginx\rThis command installs the nginx chart from the Bitnami repo as a release named my-nginx.\n5️⃣ Verify the Installation helm list kubectl get all\r🧰 Helm Is Like APT/YUM for Kubernetes Platform Install Method Example Linux apt install nginx Installs NGINX on system Kubernetes helm install nginx Installs NGINX in cluster 🧱 Helm Components Overview Component Description Chart Packaged application with Kubernetes templates Repository Collection of charts (public or private) Release Installed instance of a chart in your cluster Helm CLI Interface to install, upgrade, uninstall, or inspect charts 📦 Helm Chart Anatomy A Helm chart is a structured directory containing:\nmychart/ ├── Chart.yaml # Chart metadata ├── values.yaml # Default config values ├── templates/ # Kubernetes YAML templates ├── charts/ # Subcharts (optional) └── README.md # Documentation (optional)\r🛠️ Create a Chart helm create myapp\r🚢 Helm Repositories Helm repositories host charts and can be added easily:\nhelm repo add bitnami https://charts.bitnami.com/bitnami helm repo update helm repo list\r🚀 Helm Releases A release is a deployed instance of a chart.\nCommon Release Commands: # Install helm install my-nginx bitnami/nginx # List helm list # Upgrade helm upgrade my-nginx bitnami/nginx # Roll back helm rollback my-nginx 1 # Uninstall helm uninstall my-nginx\r🔧 Customizing Installations Using --set (inline): helm install my-nginx bitnami/nginx \\ --set service.type=NodePort \\ --set replicaCount=2\rUsing --values (file): helm install my-nginx bitnami/nginx -f custom-values.yaml\rCombine both: helm install my-nginx bitnami/nginx \\ -f base.yaml \\ --set service.type=LoadBalancer\r🔍 Preview and Debug Charts Preview manifests without installing: helm template my-nginx bitnami/nginx\rDry-run install: helm install my-nginx bitnami/nginx --dry-run --debug\r📥 Get and Customize Chart Values Show default values: helm show values bitnami/nginx\rSave for customization: helm show values bitnami/nginx \u003e custom-values.yaml\rThen install with:\nhelm install my-nginx bitnami/nginx -f custom-values.yaml\r📄 Get Values from a Running Release helm get values my-nginx -n default --all\r🧠 Helm v2 vs v3 Feature Helm v2 Helm v3 Tiller Component ✅ Required ❌ Removed Security (RBAC) Complex Simplified CRD Support Via Hooks Native Support Release Namespacing Global Scoped to Namespace Chart Repositories Helm Hub only Helm Hub + OCI support Release Storage ConfigMaps Kubernetes Secrets Upgrade Strategy Two-step (client + Tiller) Single-step (client-only) Helm v3 is recommended. Use the 2to3 plugin to migrate from Helm v2.\n🧰 Common Helm CLI Reference # Add repo helm repo add \u003cname\u003e \u003curl\u003e # Update repos helm repo update # Search helm search repo \u003ckeyword\u003e # Install helm install \u003crelease-name\u003e \u003cchart\u003e # Upgrade helm upgrade \u003crelease-name\u003e \u003cchart\u003e # Rollback helm rollback \u003crelease-name\u003e \u003crevision\u003e # Uninstall helm uninstall \u003crelease-name\u003e # Get installed values helm get values \u003crelease-name\u003e -n \u003cnamespace\u003e --all # Show default values helm show values \u003cchart-name\u003e\r✅ Summary Helm simplifies app deployment on Kubernetes via reusable charts. Works with your kubeconfig—no need for server-side components. Helm v3 is modern, secure, and CI/CD-friendly. Start by using existing charts, then build and customize your own. Mastering Helm is essential for Kubernetes-based DevOps and GitOps workflows.",
    "description": "📦 Session 1: Introduction to Helm Helm is the package manager for Kubernetes, designed to simplify deployment, configuration, and lifecycle management of Kubernetes applications using reusable packages called charts.\n⚙️ Prerequisites Before using Helm, ensure the following:\n✅ A working Kubernetes cluster ✅ kubectl configured to access the cluster ✅ Helm CLI installed on your local system 🔧 Install Helm curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\r🧩 Verify Helm Installation helm version\r🌐 How Helm Connects to Kubernetes Helm does not need a server component (like Tiller in v2). It uses:",
    "tags": [],
    "title": "Session 1: Introduction to Helm",
    "uri": "/helm/session01/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Vmware Vsphere",
    "content": "🧠 VMware Concepts: DRS vs HA, vMotion vs sMotion This document outlines the differences between VMware DRS, HA, vMotion, and Storage vMotion, which are key features of vSphere for availability, load balancing, and live migration.\n🔀 DRS (Distributed Resource Scheduler) Feature Description Purpose Automatically balances workloads across hosts based on CPU/RAM usage Type Load balancing and resource management Requires vCenter, shared storage, vMotion enabled Use Case Avoid resource contention, optimize performance ✅ Example: VM is consuming high CPU on Host A → DRS moves it to Host B (less loaded) using vMotion. ⚡ HA (High Availability) Feature Description Purpose Restarts VMs on other hosts if a host fails Type Availability and failover mechanism Requires vCenter, shared storage (for VM files), ESXi hosts in cluster Use Case Minimize downtime from host hardware failure ✅ Example: Host A fails → HA restarts its VMs automatically on Host B. 🔄 vMotion Feature Description Purpose Live migrate a running VM from one ESXi host to another without downtime Migrates VM’s memory and CPU state, not disk Requires Shared storage (e.g., NFS, iSCSI, VMFS) and vMotion network Use Case Maintenance, Load Balancing (via DRS), zero-downtime migration ✅ Example: Move a VM from Host A to Host B while it’s running, with no downtime. 💽 Storage vMotion (sMotion) Feature Description Purpose Move a VM’s virtual disk files (VMDKs) between datastores, live Migrates Only storage, not the compute/CPU/memory Requires Datastores accessible to the host Use Case Balance storage, move to faster/larger datastore, maintenance of old storage ✅ Example: VM stays on Host A, but its VMDK is moved from Datastore1 to Datastore2. 🧩 Summary Table Feature Function What It Moves Downtime? Use Case DRS Load balancing VMs between hosts (uses vMotion) ❌ No Optimize performance HA Failover recovery Restarts VMs ✅ Brief Host failure recovery vMotion Live VM migration Memory \u0026 CPU state ❌ No Zero-downtime maintenance Storage vMotion Live storage migration VMDK files ❌ No Migrate to better/faster storage 📝 Notes vMotion and sMotion can be combined to move both compute and storage (called Enhanced vMotion). DRS uses vMotion under the hood to move VMs. HA is reactive (after failure), DRS is proactive (performance/load-based). ✅ These features are essential for maintaining high availability, flexibility, and performance in VMware environments.",
    "description": "🧠 VMware Concepts: DRS vs HA, vMotion vs sMotion This document outlines the differences between VMware DRS, HA, vMotion, and Storage vMotion, which are key features of vSphere for availability, load balancing, and live migration.\n🔀 DRS (Distributed Resource Scheduler) Feature Description Purpose Automatically balances workloads across hosts based on CPU/RAM usage Type Load balancing and resource management Requires vCenter, shared storage, vMotion enabled Use Case Avoid resource contention, optimize performance ✅ Example: VM is consuming high CPU on Host A → DRS moves it to Host B (less loaded) using vMotion. ⚡ HA (High Availability) Feature Description Purpose Restarts VMs on other hosts if a host fails Type Availability and failover mechanism Requires vCenter, shared storage (for VM files), ESXi hosts in cluster Use Case Minimize downtime from host hardware failure ✅ Example: Host A fails → HA restarts its VMs automatically on Host B. 🔄 vMotion Feature Description Purpose Live migrate a running VM from one ESXi host to another without downtime Migrates VM’s memory and CPU state, not disk Requires Shared storage (e.g., NFS, iSCSI, VMFS) and vMotion network Use Case Maintenance, Load Balancing (via DRS), zero-downtime migration ✅ Example: Move a VM from Host A to Host B while it’s running, with no downtime. 💽 Storage vMotion (sMotion) Feature Description Purpose Move a VM’s virtual disk files (VMDKs) between datastores, live Migrates Only storage, not the compute/CPU/memory Requires Datastores accessible to the host Use Case Balance storage, move to faster/larger datastore, maintenance of old storage ✅ Example: VM stays on Host A, but its VMDK is moved from Datastore1 to Datastore2. 🧩 Summary Table Feature Function What It Moves Downtime? Use Case DRS Load balancing VMs between hosts (uses vMotion) ❌ No Optimize performance HA Failover recovery Restarts VMs ✅ Brief Host failure recovery vMotion Live VM migration Memory \u0026 CPU state ❌ No Zero-downtime maintenance Storage vMotion Live storage migration VMDK files ❌ No Migrate to better/faster storage 📝 Notes vMotion and sMotion can be combined to move both compute and storage (called Enhanced vMotion). DRS uses vMotion under the hood to move VMs. HA is reactive (after failure), DRS is proactive (performance/load-based). ✅ These features are essential for maintaining high availability, flexibility, and performance in VMware environments.",
    "tags": [],
    "title": "VMware DRS vs HA, vMotion vs Storage vMotion",
    "uri": "/vmware/vmware01/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Deploy a .NET Core Web API using Docker and Kubernetes",
    "content": "📦 What is a Container? A container is a lightweight, portable, and isolated runtime environment that bundles:\nYour application code All necessary dependencies (libraries, binaries, configs) Environment variables A minimal runtime Containers ensure that your application runs consistently across different environments — whether on a developer’s laptop, a test server, or in production.\n🧊 Think of a Container as: A portable box that contains everything your app needs to run — no matter where you move it, it will work the same.\n🆚 Container vs Virtual Machine (VM) Feature Container Virtual Machine (VM) Startup Time Seconds Minutes Size Lightweight (MBs) Heavy (GBs) OS Isolation Shares host OS kernel Has full guest OS Performance Near-native Slight overhead Use Case Microservices, cloud-native Full OS apps, legacy support 📸 Container Architecture (Simplified) +----------------------------+\r| Host OS |\r| +----------------------+ |\r| | Container Runtime | |\r| | +------------------+ | |\r| | | Container App | | |\r| | +------------------+ | |\r| +----------------------+ |\r+----------------------------+\r✅ Why Containers? Portability: Run your app anywhere (laptop, server, cloud) Consistency: Eliminate “it works on my machine” issues Isolation: Keep apps independent and secure Efficiency: Use fewer resources than virtual machines Scalability: Easily scale containers in/out based on demand 📌 Real-world Example Suppose you’re developing a Python app with Flask that needs Python 3.10 and specific libraries.\nIf you run it on a machine without those exact versions, it may fail.\nWith a container, you bundle Python 3.10, Flask, and your app into one image. That image runs the same way on any Docker-enabled system.\n💡 Containers are essential to modern DevOps, CI/CD, and cloud-native application development.\n🐳 Docker and Dockerfile 📌 Introduction Docker is a platform that allows you to build, ship, and run applications in lightweight, portable containers. This guide walks you through:\nWhat Docker is Why it’s useful Docker architecture Writing your first Dockerfile Building and running a container 🔍 What is Docker? Docker is an open-source tool that helps developers:\nPackage applications and dependencies into a container Run containers consistently across environments Simplify deployment and scaling ✅ Key Benefits Environment consistency across dev, test, and prod Lightweight compared to virtual machines Fast startup and shutdown Isolated apps (better security and control) ⚙️ Docker Architecture Component Description Docker Engine Core runtime to build and run containers Docker Images Read-only templates used to create containers Docker Containers Running instances of Docker images Dockerfile A script to define how to build an image Docker Hub A public registry to host and share images Check the images docker images\r🚀 Run Docker Container docker run \u003cImage name\u003e\r📋 Check Running and Stopped Containers docker ps # Running containers docker ps -a # All containers\r📂 Container Logs docker logs \u003ccontainer_id\u003e\r🔐 Docker Hub Login docker login\rProvide your Docker Hub username and password.\n☁️ Tag and Push Image to Docker Hub Step 1: Tag the Image docker tag my-first-docker-app your_dockerhub_username/my-first-docker-app:latest\rStep 2: Push the Image docker push your_dockerhub_username/my-first-docker-app:latest\rYou can now access it on https://hub.docker.com.\n🧹 Docker Cleanup Commands docker rm \u003ccontainer_id\u003e # Remove container docker rmi \u003cimage_id\u003e # Remove image docker system prune -f # Remove unused data\rTasks 01 Create a mysql db container check the logs if this is failed fix and rerun try to Access you db Convert running container into an image and push to dockerhub. Task 02 Create a container with volumes docker run -d --name test01 -v \u003chostlocation:Containerlocation\u003e nginx Create a container to expose the app to access from browser. docker run -d --name test01 -p 80:80 nginx 🧱 What is a Dockerfile? A Dockerfile is a text file that contains step-by-step instructions on how to create a Docker image.\nConceptual Flow:\nDockerfile → Docker Image → Docker Container\n🔧 Common Instructions Instruction Purpose FROM Base image to build from WORKDIR Set working directory COPY Copy files from host to container RUN Execute commands during image build CMD Default command to run on start EXPOSE Document container’s port 🏗️ Sample Project – Python App in Docker 📁 Directory Structure myapp/\n├── app.py\n└── Dockerfile\n📝 app.py print(\"Hello from Docker!\")\r🛠️ Dockerfile # Use base image FROM python:3.10-slim # Set working directory WORKDIR /app # Copy app code COPY app.py . # Run the script CMD [\"python\", \"app.py\"]\r🧪 Build and Run the Docker Container 🔨 Step 1: Build the Image docker build -t my-first-docker-app .\r🚀 Step 2: Run the Container docker run my-first-docker-app\r✅ Output Hello from Docker!\n🧹 Docker Cleanup Commands docker ps -a # List all containers docker rm \u003ccontainer-id\u003e # Remove a specific container docker images # List all images docker rmi \u003cimage-id\u003e # Remove a specific image\r🆚 Docker CMD vs ENTRYPOINT: What’s the Difference? When defining a Dockerfile, you typically use either CMD or ENTRYPOINT to specify what command should be run when the container starts.\nWhile they may look similar, they serve different purposes and behave differently.\n🔹 CMD Provides default arguments for the container’s execution. Can be overridden by command-line arguments passed with docker run. Only one CMD instruction is allowed in a Dockerfile (if multiple are present, only the last is used). ✅ Example FROM ubuntu CMD [\"echo\", \"Hello from CMD\"]\rdocker build -t cmd-example . docker run cmd-example # Output: Hello from CMD docker run cmd-example echo Hi # Output: Hi\r🔸 ENTRYPOINT Defines the main command that cannot be overridden by arguments passed in docker run. It always runs, and CLI arguments are passed as parameters to it. ✅ Example FROM ubuntu ENTRYPOINT [\"echo\", \"Hello from ENTRYPOINT\"]\rdocker build -t entrypoint-example . docker run entrypoint-example # Output: Hello from ENTRYPOINT docker run entrypoint-example User123 # Output: Hello from ENTRYPOINT User123\r🔄 Using ENTRYPOINT with CMD You can use ENTRYPOINT to define the main command and CMD to provide default parameters.\nFROM ubuntu ENTRYPOINT [\"echo\"] CMD [\"Hello from both\"]\rdocker run both-example # Output: Hello from both docker run both-example \"Custom msg\" # Output: Custom msg\r🧠 Summary Feature CMD ENTRYPOINT Overridable? ✅ Yes 🚫 No (executes always) Use case Default arguments Fixed main process Shell/Exec support Both Both Best used for Flexibility Wrapper for legacy tools, enforced run behavior 🔍 Use ENTRYPOINT when your container should always run a specific binary, and CMD to supply optional default arguments.\n📂 Dockerfile: COPY vs ADD – What’s the Difference? Both COPY and ADD are Dockerfile instructions used to transfer files from your local system into a Docker image during the build process. However, they are not identical.\n🟦 COPY Purpose: Simple file/directory copy from local context into the image. Behavior: Only copies files and directories. No extra features (e.g., does not extract archives or support URLs). ✅ Syntax COPY \u003csrc\u003e \u003cdest\u003e\r✅ Example COPY app.py /app/ COPY config/ /app/config/\r🟨 ADD Purpose: More powerful than COPY, but also more error-prone. Supports: File copying Automatic tar archive extraction Remote URL downloads ✅ Syntax ADD \u003csrc\u003e \u003cdest\u003e\r✅ Example (with local files) ADD app.tar.gz /app/ # Automatically extracts to /app/\r⚠️ Example (with URL) ADD https://example.com/file.txt /app/file.txt\r⚖️ COPY vs ADD: Feature Comparison Feature COPY ADD Copy local files ✅ Yes ✅ Yes Extract tar archives ❌ No ✅ Yes Download from URLs ❌ No ✅ Yes Simpler \u0026 more predictable ✅ Yes ❌ No 🧠 Best Practice 🛡️ Use COPY by default. Only use ADD if you need its special features like auto-extraction or remote downloads.\n💡 Example: When to Use What # Prefer COPY for clarity COPY . /app/ # Use ADD only when required ADD myapp.tar.gz /app/ # Unpacks the archive ADD https://example.com/config.yaml /app/config.yaml\r🏗️ Docker Multi-Stage Builds 🔍 What Are Multi-Stage Builds? Multi-stage builds allow you to use multiple FROM instructions in a single Dockerfile to:\nSeparate the build environment from the runtime image Minimize final image size Improve security and performance ✅ Why Use Multi-Stage Builds? In traditional Docker builds:\nBuild tools, compilers, and source files get bundled into the final image This bloats the image and exposes internal code and tools Multi-stage builds solve this by building your app in one stage, then copying only what’s needed to a second minimal image.\n🛠️ Sample Dockerfile: Go Application # Stage 1: Builder FROM golang:1.21 AS builder WORKDIR /app COPY . . RUN go build -o myapp # Stage 2: Final image FROM alpine:3.19 WORKDIR /app COPY --from=builder /app/myapp . CMD [\"./myapp\"]\r📋 Step-by-Step Explanation First stage (builder): Uses golang image to compile the application Output is the binary myapp Second stage: Uses lightweight alpine image Copies only the binary from the builder Runs the binary using CMD ⚖️ Advantages 🧹 Cleaner: Only final artifacts in runtime image 🔐 Secure: No compilers, secrets, or source code left behind 📦 Lightweight: Smaller and faster image 🔧 Additional Notes You can name stages using AS \u003cname\u003e and refer to them with --from=\u003cname\u003e You can have more than two stages (e.g., test, build, package) Multi-stage builds are supported in Docker 17.05+ Maven Build Example Clone the Maven sample Project git clone https://github.com/khushiramsingh680/studentapp.git\rCreate a Dockerfile # Stage 1: Builder FROM maven:3.3-jdk-8 AS builder WORKDIR /app COPY . . RUN mvn clean install FROM tomcat WORKDIR /usr/local/tomcat/webapps COPY --from=builder /app/target/studentapp-2.5-SNAPSHOT.war .\rNow Generate an image docker build -t \u003cname\u003e .\rCreate a container using this image docker run -d -p 88:8080 \u003cimage name\u003e\rAccess your app from Browser ip:88/studentapp-2.5-SNAPSHOT/\rContainer UI Tool Portainer",
    "description": "Learn Docker concepts, architecture, and how to write your first Dockerfile with real examples.",
    "tags": [
      "Docker",
      "Dockerfile",
      "Containers",
      "Devops",
      "Tutorial"
    ],
    "title": "Session 01",
    "uri": "/dotnet/day01/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Introduction to Helm",
    "content": "🎯 Session 2: Creating and Hosting Custom Helm Charts In this session, you’ll learn to:\n✅ Create your own Helm charts from scratch ✅ Customize templates and use values effectively ✅ Understand and use _helpers.tpl ✅ Host charts on GitHub as a Helm repository ✅ Apply real-world scenarios (Ingress, ConfigMap, HPA) 🛠️ Step 1: Create a Custom Chart helm create nginx-demo cd nginx-demo\rThis creates the following structure:\nnginx-demo/ ├── charts/ ├── Chart.yaml ├── templates/ │ ├── deployment.yaml │ ├── _helpers.tpl │ ├── hpa.yaml │ ├── ingress.yaml │ ├── service.yaml │ ├── configmap.yaml │ └── tests/ └── values.yaml\r📄 What is _helpers.tpl? _helpers.tpl is a special file used to define reusable template snippets using Go’s template syntax. It’s where you can define helper functions like naming conventions or labels, which you can include in other templates using {{ include \"name\" . }}.\n✅ Example: _helpers.tpl {{- define \"nginx-demo.name\" -}}\rnginx\r{{- end }}\r{{- define \"nginx-demo.fullname\" -}}\r{{ .Release.Name }}-nginx\r{{- end }}\r{{- define \"nginx-demo.labels\" -}}\rapp.kubernetes.io/name: {{ include \"nginx-demo.name\" . }}\rhelm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version }}\rapp.kubernetes.io/instance: {{ .Release.Name }}\rapp.kubernetes.io/managed-by: {{ .Release.Service }}\r{{- end }}\r{{- define \"nginx-demo.serviceAccountName\" -}}\r{{- if .Values.serviceAccount.name }}\r{{ .Values.serviceAccount.name }}\r{{- else }}\r{{ include \"nginx-demo.fullname\" . }}\r{{- end }}\r{{- end }}\r📌 Usage in Other Templates metadata: name: {{ include \"nginx-demo.fullname\" . }} labels: {{- include \"nginx-demo.labels\" . | nindent 4 }}\rThis avoids duplication and keeps your chart DRY (Don’t Repeat Yourself).\n📦 Custom values.yaml replicaCount: 2 image: repository: nginx pullPolicy: IfNotPresent tag: \"1.25.2\" service: type: ClusterIP port: 80 ingress: enabled: true className: \"nginx\" annotations: nginx.ingress.kubernetes.io/rewrite-target: / hosts: - host: nginx.local paths: - path: / pathType: Prefix config: message: \"Welcome to Helm-powered NGINX!\" autoscaling: enabled: true minReplicas: 2 maxReplicas: 5 targetCPUUtilizationPercentage: 70 resources: {} nodeSelector: {} tolerations: [] affinity: {}\r⚙️ Templates Overview 🔸 deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: {{ include \"nginx-demo.fullname\" . }} labels: {{- include \"nginx-demo.labels\" . | nindent 4 }} spec: replicas: {{ .Values.replicaCount }} selector: matchLabels: app: {{ include \"nginx-demo.name\" . }} template: metadata: labels: app: {{ include \"nginx-demo.name\" . }} spec: containers: - name: nginx image: \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\" imagePullPolicy: {{ .Values.image.pullPolicy }} ports: - containerPort: 80 env: - name: APP_MESSAGE valueFrom: configMapKeyRef: name: {{ include \"nginx-demo.fullname\" . }} key: appMessage\r🔸 service.yaml apiVersion: v1 kind: Service metadata: name: {{ include \"nginx-demo.fullname\" . }} spec: type: {{ .Values.service.type }} ports: - port: {{ .Values.service.port }} targetPort: 80 selector: app: {{ include \"nginx-demo.name\" . }}\r🔸 configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: {{ include \"nginx-demo.fullname\" . }} data: appMessage: {{ .Values.config.message | quote }}\r🔸 ingress.yaml {{- if .Values.ingress.enabled }} apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: {{ include \"nginx-demo.fullname\" . }} annotations: {{- range $key, $value := .Values.ingress.annotations }} {{ $key }}: {{ $value | quote }} {{- end }} spec: ingressClassName: {{ .Values.ingress.className }} rules: {{- range .Values.ingress.hosts }} - host: {{ .host }} http: paths: {{- range .paths }} - path: {{ .path }} pathType: {{ .pathType }} backend: service: name: {{ include \"nginx-demo.fullname\" $ }} port: number: {{ $.Values.service.port }} {{- end }} {{- end }} {{- end }}\r🔸 hpa.yaml {{- if .Values.autoscaling.enabled }} apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: {{ include \"nginx-demo.fullname\" . }} spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: {{ include \"nginx-demo.fullname\" . }} minReplicas: {{ .Values.autoscaling.minReplicas }} maxReplicas: {{ .Values.autoscaling.maxReplicas }} metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: {{ .Values.autoscaling.targetCPUUtilizationPercentage }} {{- end }}\r🧪 Run the Chart helm install my-nginx ./nginx-demo helm test my-nginx\r🌐 Host Helm Charts on GitHub Step 1: Create and Package mkdir helm-registry \u0026\u0026 cd helm-registry helm create order helm create delivery helm package order helm package delivery helm repo index .\rStep 2: Push to GitHub git init git remote add origin https://github.com/\u003cyour-username\u003e/helm-registry.git git add . git commit -m \"Add Order and Delivery Charts\" git push -u origin main\rEnable GitHub Pages on the repository (Settings → Pages).\nStep 3: Add and Use Repo helm repo add teamcharts https://\u003cyour-username\u003e.github.io/helm-registry helm repo update helm install order-app teamcharts/order helm install delivery-app teamcharts/delivery\r✅ Summary Topic Description _helpers.tpl Defines reusable template logic (naming, labels, etc.) values.yaml Central place for all configuration values Templates Refer to values and helpers using Go templating Hosting GitHub Pages serves .tgz charts and index.yaml as a repo Real-World Additions ConfigMap, Ingress, Autoscaling (HPA) support",
    "description": "🎯 Session 2: Creating and Hosting Custom Helm Charts In this session, you’ll learn to:\n✅ Create your own Helm charts from scratch ✅ Customize templates and use values effectively ✅ Understand and use _helpers.tpl ✅ Host charts on GitHub as a Helm repository ✅ Apply real-world scenarios (Ingress, ConfigMap, HPA) 🛠️ Step 1: Create a Custom Chart helm create nginx-demo cd nginx-demo\rThis creates the following structure:\nnginx-demo/ ├── charts/ ├── Chart.yaml ├── templates/ │ ├── deployment.yaml │ ├── _helpers.tpl │ ├── hpa.yaml │ ├── ingress.yaml │ ├── service.yaml │ ├── configmap.yaml │ └── tests/ └── values.yaml\r📄 What is _helpers.tpl? _helpers.tpl is a special file used to define reusable template snippets using Go’s template syntax. It’s where you can define helper functions like naming conventions or labels, which you can include in other templates using {{ include \"name\" . }}.",
    "tags": [],
    "title": "Session 2: Creating and Hosting Custom Helm Charts",
    "uri": "/helm/session02/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Deploy a .NET Core Web API using Docker and Kubernetes",
    "content": "📦 Docker Compose – Manage Multi-Container Applications 📌 What is Docker Compose? Docker Compose is a tool used to define and run multi-container Docker applications.\nYou define the services, networks, and volumes your app needs in a docker-compose.yml file, and bring everything up with a single command.\n✅ Benefits of Docker Compose Easy to manage complex applications Reproducible environments Centralized configuration Supports custom networks and volumes Ideal for local development and CI pipelines Docker Compose Installation 🧱 Example Project Structure myapp/\r├── backend/\r│ └── app.py\r├── frontend/\r│ └── index.html\r├── db/\r│ └── init.sql\r├── docker-compose.yml\r└── Dockerfile (for backend)\rRun this script to have the structure created automatically #!/bin/bash # Create directories mkdir -p myapp/backend myapp/frontend myapp/db cd myapp # Create backend/app.py cat \u003c\u003cEOF \u003e backend/app.py from flask import Flask app = Flask(__name__) @app.route(\"/\") def hello(): return \"Hello from the Backend Flask App!\" if __name__ == \"__main__\": app.run(host=\"0.0.0.0\", port=5000) EOF # Create frontend/index.html cat \u003c\u003cEOF \u003e frontend/index.html \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eFrontend\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eHello from Frontend\u003c/h1\u003e \u003c/body\u003e \u003c/html\u003e EOF # Create db/init.sql cat \u003c\u003cEOF \u003e db/init.sql CREATE TABLE IF NOT EXISTS messages ( id SERIAL PRIMARY KEY, text VARCHAR(255) NOT NULL ); EOF # Create Dockerfile (for backend) cat \u003c\u003cEOF \u003e Dockerfile FROM python:3.10-slim WORKDIR /app COPY backend/ . RUN pip install flask CMD [\"python\", \"app.py\"] EOF # Create docker-compose.yml cat \u003c\u003cEOF \u003e docker-compose.yml version: \"3.9\" services: backend: build: . ports: - \"5000:5000\" depends_on: - db frontend: image: nginx:alpine ports: - \"80:80\" volumes: - ./frontend:/usr/share/nginx/html:ro db: image: postgres:13 environment: POSTGRES_USER: myuser POSTGRES_PASSWORD: mypass POSTGRES_DB: mydb volumes: - db_data:/var/lib/postgresql/data - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro volumes: db_data: EOF echo \"✅ Project structure created successfully in ./myapp\"\r📜 Sample docker-compose.yml version: \"3.9\" services: backend: build: ./backend ports: - \"5000:5000\" depends_on: - db frontend: image: nginx:alpine ports: - \"80:80\" volumes: - ./frontend:/usr/share/nginx/html db: image: postgres:13 environment: POSTGRES_USER: myuser POSTGRES_PASSWORD: mypass POSTGRES_DB: mydb volumes: - db_data:/var/lib/postgresql/data volumes: db_data:\r🚀 Common Docker Compose Commands docker-compose up # Start all services docker-compose up -d # Run in detached mode docker-compose down # Stop and remove all containers docker-compose ps # List running services docker-compose logs # View logs for all services docker-compose build # Build services docker-compose restart backend # Restart a specific service\r🔄 Rebuild and Restart docker-compose down --volumes # Remove all volumes too docker-compose up --build # Rebuild and start\r🧪 Compose for Local Development Use Compose to simulate a full application stack locally:\nBackend (e.g., Flask/Django/Node) Frontend (e.g., React/Vue/Angular) Database (e.g., PostgreSQL/MySQL) Proxy/Load balancer (e.g., NGINX) 🧠 Tips and Best Practices Use .env files for secrets and environment config Use depends_on for startup order (not readiness checks) Bind volumes for live code changes Version-lock your base images ✅ Docker Compose is a must-have for developing, testing, and deploying multi-container apps with consistency.",
    "description": "Learn how to use Docker Compose to define and run multi-container applications with ease.",
    "tags": [
      "Docker",
      "Docker-Compose",
      "Containers",
      "Devops"
    ],
    "title": "Session 02",
    "uri": "/dotnet/day02/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Deploy a .NET Core Web API using Docker and Kubernetes",
    "content": "Getting Started with Kubernetes Kubernetes (K8s) is an open-source system for automating deployment, scaling, and management of containerized applications.\n🚀 Prerequisites Basic knowledge of containers (e.g., Docker) A running Kubernetes cluster (Minikube, Kind, or a managed service like GKE, EKS, AKS) kubectl installed and configured 🛠 Install kubectl command to manage kubernetes # Install kubectl curl -LO \"https://dl.k8s.io/release/$(curl -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" chmod +x kubectl \u0026\u0026 mv kubectl /usr/local/bin/\rAKS Deployment Guide A step-by-step guide to deploy Azure Kubernetes Service (AKS) using Azure CLI.\n📌 Prerequisites An active Azure subscription Azure CLI installed (az --version to check) Link for Az cli installation Logged into Azure: az login --use-device-code\rCheck your azure subscription az account list - table\rCheck login status az account show\rCreate a Resource Group az group create --name myResourceGroup --location centralindia\rCreate AKS Cluster az aks create \\ --resource-group myResourceGroup \\ --name myAKSCluster \\ --location centralindia \\ --node-count 1 \\ --node-vm-size Standard_B2s \\ --generate-ssh-keys\rRegister the Missing Resource Provider if get an error az provider register --namespace Microsoft.OperationalInsights az provider show --namespace Microsoft.OperationalInsights --query \"registrationState\"\rRegister all required add on for AKS for ns in Microsoft.ContainerService Microsoft.OperationalInsights Microsoft.Insights Microsoft.Network Microsoft.Compute Microsoft.Storage; do az provider register --namespace $ns done\rGet AKS Credentials (Kubeconfig) az aks get-credentials --resource-group myResourceGroup --name myAKSCluster\rVerify Cluster Access kubectl get nodes\r✅ Jenkins Credential ID for AKS kubeconfig When you upload your kubeconfig file as a Secret file in Jenkins, you choose an ID for it. Examples:\naks-kubeconfig kubeconfig prod-aks (Any custom name you prefer) This ID is used in the Jenkins pipeline to reference the kubeconfig file.\n✅ Example: Upload \u0026 Use aks-kubeconfig 📌 In Jenkins: Navigate to Manage Jenkins → Credentials Choose the appropriate scope (e.g., Global, Folder, etc.) Click “Add Credentials” Choose “Secret file” Upload your kubeconfig file Set the ID to: aks-kubeconfig 📋 Jenkins Pipeline (Declarative) Example pipeline { agent any environment { KUBECONFIG = \"${WORKSPACE}/kubeconfig\" } stages { stage('Use AKS Kubeconfig') { steps { withCredentials([file(credentialsId: 'aks-kubeconfig', variable: 'KUBECONFIG_FILE')]) { sh ''' cp $KUBECONFIG_FILE $KUBECONFIG chmod 600 $KUBECONFIG kubectl get nodes ''' } } } } }\r🛠️ Kompose - Convert Docker Compose to Kubernetes YAML Kompose is a tool that helps you convert your docker-compose.yml into Kubernetes resource manifests.\n✅ What Kompose Does Kompose automatically converts:\nDocker Compose services ➡️ Kubernetes Deployments Exposed ports ➡️ Kubernetes Services Volumes ➡️ PersistentVolumeClaims Environment variables ➡️ ConfigMaps or inline in Pods 📦 Install Kompose 🔧 On Linux / macOS curl -L https://github.com/kubernetes/kompose/releases/download/v1.30.0/kompose-linux-amd64 -o kompose chmod +x kompose sudo mv kompose /usr/local/bin/\r🔄 Convert Docker Compose to Kubernetes Manifests Navigate to the folder where your docker-compose.yml is located: Run: kompose convert\rTo deploy directly to your cluster: kompose up\rTo remove kompose down\rYou may have to take care of the labels and ports assigned to svc and pods .",
    "description": "Getting Started with Kuberntes",
    "tags": [
      "Jenkins",
      "Docker",
      "Docker-Compose",
      "Ci-Cd",
      "Devops",
      "Pipeline"
    ],
    "title": "Session 03",
    "uri": "/dotnet/day03/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Deploy a .NET Core Web API using Docker and Kubernetes",
    "content": "🚀 CI/CD Explained CI/CD stands for:\nCI → Continuous Integration CD → Continuous Delivery / Continuous Deployment These are essential practices in DevOps that help teams deliver software faster, more reliably, and with confidence.\n🔧 1. What is CI (Continuous Integration)? ✅ CI automates the process of merging and testing code frequently.\nKey Concepts: Developers push code frequently (e.g., daily) Code is automatically built and tested via pipelines Prevents “integration hell” at release time Example Activities: Compile/build the app Run unit tests Lint code Package artifacts (e.g., .jar, .tar.gz) 📦 2. What is CD? CD has two meanings:\nContinuous Delivery or Continuous Deployment\nLet’s break it down:\n✅ 2A. Continuous Delivery Automates delivery of code to a staging environment or manual approval gate.\nCode is tested and ready to deploy Human approval is needed for production Reduces time between development and release 🧪 Ideal for teams that want control and automated testing, but manual production releases.\n🚀 2B. Continuous Deployment Fully automates deployment to production with no manual steps.\nEvery successful commit is deployed to production Requires robust test automation Zero manual intervention 🔁 Ideal for high-frequency release teams (e.g., Netflix, Amazon)\n🔁 CI/CD Pipeline Example Flow Commit → CI Build → Unit Test → Lint → Integration Test → Package → CD Staging → Manual Approval → CD Production\rIn Continuous Deployment, the Manual Approval step is removed.\n🧠 Benefits of CI/CD Benefit CI CD Early bug detection ✅ ✅ Faster releases ✅ ✅ Automation ✅ Build/Test ✅ Deploy/Test Developer confidence ✅ ✅ Customer satisfaction ✅ Faster feature delivery 🛠️ Tools for CI/CD Category Popular Tools CI Pipelines Jenkins, GitLab CI, CircleCI CD Tools ArgoCD, Spinnaker, Flux Testing JUnit, Pytest, Selenium Containers Docker, Podman Orchestration Kubernetes, Nomad 🧩 Summary Table Term Description CI Automate build and test after every commit Continuous Delivery Ready to deploy with approval Continuous Deployment Automatically deploy to production 🧰 Jenkins Setup and Docker Compose Pipeline Guide 🧱 Part 1: Install Jenkins (Ubuntu/Debian) 🔹 Step 1: Install Java (required) sudo apt update sudo apt install openjdk-17-jdk -y\r🔹 Step 2: Add Jenkins repository curl -fsSL https://pkg.jenkins.io/debian/jenkins.io.key | sudo tee \\ /usr/share/keyrings/jenkins-keyring.asc \u003e /dev/null echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \\ https://pkg.jenkins.io/debian binary/ | sudo tee \\ /etc/apt/sources.list.d/jenkins.list \u003e /dev/null\r🔹 Step 3: Install Jenkins sudo apt update sudo apt install jenkins -y\r🔹 Step 4: Start and Enable Jenkins sudo systemctl enable jenkins sudo systemctl start jenkins\r📬 Step 5: Access Jenkins Open in browser:\nhttp://\u003cyour-server-ip\u003e:8080\rGet initial admin password: sudo cat /var/lib/jenkins/secrets/initialAdminPassword\rCopy that password to the browser and finish setup.\n🐳 Part 2: Install Docker \u0026 Docker Compose Install Docker sudo apt install ca-certificates curl gnupg -y sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \\ sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg echo \\ \"deb [arch=$(dpkg --print-architecture) \\ signed-by=/etc/apt/keyrings/docker.gpg] \\ https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | \\ sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null sudo apt update sudo apt install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y\rAllow Jenkins to run Docker sudo usermod -aG docker jenkins sudo systemctl restart jenkins\r🔁 You may also need to reboot or restart Jenkins for group changes to apply.\n🧪 Part 3: Verify Docker Access from Jenkins Test in Jenkins (via freestyle or pipeline job): pipeline { agent any stages { stage('Docker Test') { steps { sh 'docker version' sh 'docker info' } } } }\r🚀 Part 4: Sample Jenkins Pipeline to Run Docker Compose App pipeline { agent any environment { COMPOSE_PROJECT_DIR = \"${WORKSPACE}/myapp\" } stages { stage('Checkout') { steps { git 'https://github.com/nirpendra83/docker-compose.git' } } stage('Build and Deploy') { steps { dir('myapp') { sh 'docker-compose down --volumes || true' sh 'docker-compose up -d --build' } } } stage('Health Check') { steps { sh 'sleep 5 \u0026\u0026 curl -f http://localhost:5000' } } stage('Shutdown') { steps { dir('myapp') { sh 'docker-compose down' } } } } post { always { echo '✅ Pipeline complete. Clean up done.' } } }\r🧠 Tips Add SSH credentials if cloning from private Git repositories Use docker-compose logs for troubleshooting Avoid using localhost for health checks if Jenkins runs in Docker Let me know if you want a .sh script to automate this or a Jenkinsfile zipped with the myapp/ project! I can generate and upload it for you.\n💡 Jenkins Declarative Pipeline Guide The Declarative Pipeline in Jenkins is a structured way to define CI/CD workflows using a Jenkinsfile. It is easier to read, validate, and maintain compared to Scripted Pipelines.\n🧱 1. Basic Structure pipeline { agent any stages { stage('Example') { steps { echo 'Hello World' } } } }\r🚀 2. agent Block The agent defines where the pipeline or a specific stage runs.\n🔹 Global Agent agent any\r🔹 Label-based Agent agent { label 'docker-node' }\r🔹 Docker Agent agent { docker { image 'python:3.10' args '-p 5000:5000' } }\r🔹 No Agent Globally (define per stage) pipeline { agent none stages { stage('Build') { agent any steps { echo \"Building...\" } } } }\r🌍 3. environment Block Defines environment variables, globally or per stage.\nenvironment { MY_ENV = 'production' PATH = \"/custom/bin:${env.PATH}\" }\r🧪 4. parameters Block Used for user input when starting a pipeline manually.\nparameters { string(name: 'VERSION', defaultValue: '1.0.0', description: 'Release version') booleanParam(name: 'RUN_TESTS', defaultValue: true, description: 'Run tests?') }\rUse with: ${params.VERSION}, ${params.RUN_TESTS}\n🧱 5. stages and steps Stages are logical divisions like “Build”, “Test”, “Deploy” Steps are shell commands or Jenkins actions stages { stage('Build') { steps { echo \"Building version ${params.VERSION}\" sh 'make build' } } }\r🧼 6. post Block Defines actions to run after the pipeline or a stage, based on outcome.\npost { always { echo 'Always runs' } success { echo 'Runs on success' } failure { echo 'Runs on failure' } unstable { echo 'Runs if build is unstable' } changed { echo 'Runs if result changed since last run' } }\r🎯 7. when Block Run a stage only if conditions are met.\nstage('Deploy') { when { branch 'main' } steps { sh './deploy.sh' } }\rOther options:\nexpression { return params.RUN_TESTS } environment name: 'ENV_VAR', value: 'prod' not, anyOf, allOf for combining conditions 🔀 8. Parallel Stages stage('Test Suite') { parallel { stage('Unit Tests') { steps { sh 'pytest tests/unit' } } stage('Integration Tests') { steps { sh 'pytest tests/integration' } } } }\r🔧 9. Error Handling Explicit failure: steps { error(\"Stopping pipeline due to failure\") }\rRetry logic: steps { retry(3) { sh './sometimes-fails.sh' } }\r🧠 10. Built-in Variables Variable Description env.BUILD_ID Unique ID for the current build env.BUILD_NUMBER Build number env.JOB_NAME Name of the job params.\u003cname\u003e Access input parameters env.WORKSPACE File path of the working directory 📦 Example: Full Declarative Pipeline pipeline { agent any parameters { string(name: 'VERSION', defaultValue: '1.0.0') } environment { DEPLOY_ENV = 'staging' } stages { stage('Build') { steps { echo \"Building version ${params.VERSION}\" } } stage('Test') { steps { sh './run_tests.sh' } } stage('Deploy') { when { branch 'main' } steps { sh './deploy.sh ${params.VERSION}' } } } post { success { echo '✅ Build succeeded.' } failure { echo '❌ Build failed.' } always { echo '🧹 Cleaning up...' } } }\r✅ Declarative pipelines are YAML-like Groovy configurations that make your Jenkins workflows repeatable, testable, and easy to maintain.\nLet me know if you want this converted to a downloadable .md file or added to a GitHub repo template.",
    "description": "Install Jenkins and Run Docker Compose with Pipeline",
    "tags": [
      "Jenkins",
      "Docker",
      "Docker-Compose",
      "Ci-Cd",
      "Devops",
      "Pipeline"
    ],
    "title": "Session 04",
    "uri": "/dotnet/day04/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Introduction to Helm",
    "content": "Template Functions and Pipelines\n🧭 Helm Template Functions Cheat Sheet with Examples This document provides a comprehensive list of Helm template functions used in Helm charts, with real-world examples using .Values, .Chart, and .Release.\n🔧 Commonly Used Functions 🗝️ default – Provide a fallback value replicaCount: {{ .Values.replicaCount | default 3 }}\rIf .Values.replicaCount is not set in values.yaml, it defaults to 3.\n❗ required – Make a value mandatory apiVersion: v1 kind: Secret metadata: name: my-secret data: password: {{ required \"A password is required!\" .Values.password | b64enc }}\rapiVersion: v1 kind: Secret metadata: name: my-secret data: {{- if .Values.password }} password: {{ .Values.password | b64enc | quote }} {{- else }} password: \"\" {{- end }}\rWill throw an error at install/upgrade if password is not provided.\nHow to render yaml files from new charts helm template my-nginx01 ./nginx-demo -n helm-test --debug\r🔤 String Functions upper, lower, title, trim, replace metadata: name: {{ .Chart.Name | upper }}-{{ .Release.Name | lower }} annotations: summary: {{ .Values.summary | title | quote }}\rTransforms strings:\nhelm → HELM release-name → release-name some text → Some Text annotations: clean-name: {{ replace .Chart.Name \"-\" \"_\" }}\rReplaces hyphens (-) with underscores (_) in the chart name.\nUseful for making label-safe names.\n🔢 Number Functions add, sub, mul, div, mod resources: limits: cpu: {{ mul .Values.cpuBase .Values.cpuFactor }}\rreplicaCount: {{ add 2 3 }} # Output: 5\rPerform arithmetic using Helm values.\n📃 List Functions list, join, first, last, uniq, range ✅ Example: Looping with range and list env: {{- range $env := list \"STAGING\" \"PROD\" \"DEV\" }} - name: ENV value: {{ $env }} {{- end }}\rLoops over the list and renders each value as an environment variable.\nRendered output:\nenv: - name: ENV value: STAGING - name: ENV value: PROD - name: ENV value: DEV\r✅ Example: join – Convert a list to comma-separated string labels: environments: {{ join \",\" (list \"dev\" \"staging\" \"prod\") }}\rConverts list to string: dev,staging,prod.\n✅ Example: uniq – Remove duplicates from list uniq-values: {{ uniq (list 1 2 2 3 1) }} # Output: [1 2 3]\rRemoves duplicate values.\nUse join if you need to convert it to string for use in annotations/labels.\n🗂️ Dictionary/Object Functions dict, hasKey, pluck, keys {{- $config := dict \"env\" \"prod\" \"region\" \"us-west\" }} region: {{ $config.region }}\r{{- if hasKey .Values \"replicaCount\" }} replicas: {{ .Values.replicaCount }} {{- end }}\rThese functions help dynamically access and iterate through key-value pairs.\n🔁 Flow Control if, else, range, with {{- if .Values.enabled }} metadata: labels: enabled: \"true\" {{- else }} metadata: labels: enabled: \"false\" {{- end }}\r{{- range $key, $val := .Values.config }} {{ $key }}: {{ $val }} {{- end }}\rin Values.yaml config: timeout: 30s retries: 5 logLevel: debug\r{{- with .Values.database }} host: {{ .host }} port: {{ .port }} {{- end }}\rin Values.yaml database: host: db.example.com port: 5432\rConditional logic and scoping for clean, DRY templates.\n🔐 Crypto \u0026 Encoding b64enc, b64dec, sha256sum data: password: {{ .Values.dbPassword | b64enc }}\rhashed: {{ \"sensitive\" | sha256sum }}\rUseful for secrets, hashing, and safe encoding.\n🕒 Date \u0026 Time (Limited) annotations: generatedAt: {{ now | date \"2006-01-02T15:04:05Z07:00\" }}\rnow returns current timestamp.\nFormat it using Go time layout (2006-01-02 is the reference format).\n🧪 Example values.yaml replicaCount: 2 enabled: true summary: \"simple chart\" cpuBase: 100 cpuFactor: 2 password: \"secret123\" dbPassword: \"admin\" envList: - name: ENV value: PROD config: LOG_LEVEL: debug TIMEOUT: 30 database: host: db.example.com port: 5432 services: service1: port: 80 service2: port: 443",
    "description": "Template Functions and Pipelines\n🧭 Helm Template Functions Cheat Sheet with Examples This document provides a comprehensive list of Helm template functions used in Helm charts, with real-world examples using .Values, .Chart, and .Release.\n🔧 Commonly Used Functions 🗝️ default – Provide a fallback value replicaCount: {{ .Values.replicaCount | default 3 }}\rIf .Values.replicaCount is not set in values.yaml, it defaults to 3.\n❗ required – Make a value mandatory apiVersion: v1 kind: Secret metadata: name: my-secret data: password: {{ required \"A password is required!\" .Values.password | b64enc }}\rapiVersion: v1 kind: Secret metadata: name: my-secret data: {{- if .Values.password }} password: {{ .Values.password | b64enc | quote }} {{- else }} password: \"\" {{- end }}\rWill throw an error at install/upgrade if password is not provided.",
    "tags": [],
    "title": "Helm Functions",
    "uri": "/helm/helmfunctions/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Deploy a .NET Core Web API using Docker and Kubernetes",
    "content": "Project Link ✨ What is this? A production-ready full-stack starter kit built using modern technologies and best practices:\nFrontend: Angular 20 with Signals, Material Design, and TailwindCSS Backend: .NET 9 API implementing Clean Architecture Database: PostgreSQL 16 using Dapper ORM DevOps: Docker, GitHub Actions, and NGINX Perfect for developers who want to focus on business logic instead of spending time setting up infrastructure.\n🏗️ Why Clean Architecture? Clean Architecture helps in creating maintainable, testable, and scalable applications by separating concerns and enforcing clear boundaries between layers.\nBenefits: Independent of frameworks and UI Emphasizes testability and loose coupling Simplifies onboarding and feature extension Ensures long-term maintainability 🚀 Application Demo A Contact Management Application with:\nRole-Based Access Control (RBAC) Secure API endpoints Modular and extensible design 🔧 Technologies Used Layer Stack Frontend Angular 20, Signals, TailwindCSS, Material Backend .NET 9, Clean Architecture, Dapper ORM Database PostgreSQL 16 DevOps Docker, GitHub Actions, NGINX 🚀 Getting Started to deploy to container using docker compose 🔃 Clone the Repository git clone https://github.com/nirpendra83/clean-architecture-docker-dotnet-angular.git clean-app cd clean-app\rCreate .env File cp .env.example .env\rRun the below command docker-compose up docker-compose up -d\r🚀 Deploy the Application to Kubernetes 1. Clone the Repository git clone https://github.com/nirpendra83/clean-architecture-docker-dotnet-angular.git clean-app cd clean-app\r2. Navigate to the Kubernetes Deployment Directory and Apply Resources\ncd kubernetes kubectl apply -f .\r3. Verify the Deployment\nkubectl get pods\rJenkins Declarative Pipeline for Deploying to Kubernetes This pipeline performs the following:\nClones the Git repository (main branch) Navigates to the kubernetes folder Applies all Kubernetes YAML manifests using kubectl apply -f . Uses a Jenkins secret file credential for kubeconfig (kubeconfig-cred-id) Jenkinsfile (Declarative Pipeline) pipeline { agent any environment { REPO_URL = 'https://github.com/nirpendra83/clean-architecture-docker-dotnet-angular.git' BRANCH = 'main' } stages { stage('Clone Repository') { steps { git branch: \"${BRANCH}\", url: \"${REPO_URL}\" } } stage('Deploy to Kubernetes') { steps { withCredentials([file(credentialsId: 'kubeconfig-cred-id', variable: 'KUBECONFIG')]) { dir('kubernetes') { sh 'kubectl apply -f .' } } } } } }\rConfiguring Jenkins to Use kubeconfig as a Secret File Credential To enable your Jenkins pipeline to authenticate with the Kubernetes cluster, follow these steps to store your kubeconfig file securely and use it in your pipeline.\nStep 1: Add kubeconfig as a Secret File in Jenkins Go to Jenkins Dashboard → Manage Jenkins → Manage Credentials Select the appropriate scope (e.g., (global) or a specific folder) Click Add Credentials Choose Kind: Secret file Upload your kubeconfig file ID: Set it as kubeconfig-cred-id (or use a custom ID and update the pipeline accordingly) Optionally, add a description Click OK to save Step 2: Use the kubeconfig Secret File in Your Jenkins Pipeline In your Jenkinsfile, reference the kubeconfig credential using the withCredentials block:\nwithCredentials([file(credentialsId: 'kubeconfig-cred-id', variable: 'KUBECONFIG')]) { sh 'kubectl get pods' }",
    "description": "Production-ready starter with Angular, .NET 9, PostgreSQL, and Clean Architecture principles for scalable web apps.",
    "tags": [
      "Clean Architecture",
      "Dotnet",
      "Angular",
      "Postgresql",
      "Full-Stack",
      "Starter-Kit",
      "Devops"
    ],
    "title": "Session 05",
    "uri": "/dotnet/day05/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm",
    "content": "Prerequisites to install docker and kubernetes Linux system (Ubuntu 20.04/22.04, RHEL 8/9, or Rocky Linux) User with sudo privileges Internet connection Docker Hub account (or private container registry) Step 1: Install .NET 8 SDK on Linux Ubuntu 22.04 / 20.04 sudo apt update sudo apt install -y wget apt-transport-https software-properties-common wget https://packages.microsoft.com/config/ubuntu/22.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb sudo dpkg -i packages-microsoft-prod.deb rm packages-microsoft-prod.deb\r** Install Dot net version 8 sudo apt update sudo apt install -y dotnet-sdk-8.0\rVerify dotnet --version\rStep 2: Install Docker and Kubernetes Tools sudo apt-get update sudo apt-get install -y ca-certificates curl gnupg lsb-release sudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor | sudo tee /etc/apt/keyrings/docker.gpg \u003e /dev/null echo \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \\ https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" \\ | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null sudo apt-get update sudo apt-get install -y docker-ce docker-ce-cli containerd.io sudo systemctl enable docker sudo systemctl start docker\rInstall kubectl curl -LO \"https://dl.k8s.io/release/$(curl -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" chmod +x kubectl sudo mv kubectl /usr/local/bin/\rStep 3: Create .NET Core Web API Project dotnet new webapi -n HelloWorldApi cd HelloWorldApi dotnet run\rAdd some code to confirm it’s running In Program.cs or Startup.cs, add: Console.WriteLine(\"App started\");\rNow check again dotnet run\rCreate a Dockerfile Dockerfile # Stage 1: Build FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build WORKDIR /app # Copy csproj and restore as distinct layers COPY *.csproj ./ RUN dotnet restore # Copy the rest of the source and build COPY . ./ RUN dotnet publish -c Release -o /app/out # Stage 2: Runtime FROM mcr.microsoft.com/dotnet/aspnet:8.0 WORKDIR /app COPY --from=build /app/out . # Expose the default port EXPOSE 80 # Run the application ENTRYPOINT [\"dotnet\", \"HelloWorldApi.dll\"]\r. Build the Docker image: docker build -t helloworldapi:8 .\rRun the container docker run -d -p 8080:5000 --name hwapi helloworldapi:8\rSteps to Run .NET 8 Web App Persistently in Docker In Program.cs, ensure your app listens on 0.0.0.0: var builder = WebApplication.CreateBuilder(args); var app = builder.Build(); app.MapGet(\"/\", () =\u003e \"Hello from .NET 8 API\"); app.Run(\"http://0.0.0.0:5000\");\rAgain create an image docker build -t helloworldapi:8 . `` - Run the container now ```sh docker run -d --restart=always -p 8080:5000 --name hwapi helloworldapi:8\rAccess your app from browser ip:8080\rNow push this image to dockerhub docker login\rTag your image as per your user docker tag helloworldapi:8 nippy/helloworldapi:8\rpush your image to dockerhub docker push nippy/helloworldapi:8\rDeploy this to kubernetes (Create deployment ) helloworld-deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: name: helloworld-api spec: replicas: 1 selector: matchLabels: app: helloworld-api template: metadata: labels: app: helloworld-api spec: containers: - name: helloworld-api image: nippy/helloworldapi:8 imagePullPolicy: IfNotPresent ports: - containerPort: 80\r✅ 2. Service YAML (unchanged, helloworld-svc.yaml) apiVersion: v1 kind: Service metadata: name: helloworld-service spec: type: LoadBalancer selector: app: helloworld-api ports: - protocol: TCP port: 80 targetPort: 5000\rOR kubectl expose deployment helloworld-api --port 80 --type LoadBalancer --target-port 5000 --name test01\r🚀 3. Deploy to Kubernetes kubectl apply -f helloworld-deploy.yaml kubectl apply -f helloworld-svc.yaml\rNow check the loadBalancer IP kubectl get svc\rAccess in Browser ip:80\r3 Tier APP Complete Sample: Angular Frontend + .NET 8 Web API + PostgreSQL + Docker Compose Step 1: Folder Structure my-fullstack-app/\r├── backend/\r│ ├── Controllers/\r│ ├── Data/\r│ ├── Models/\r│ ├── Program.cs\r│ ├── appsettings.json\r│ ├── Dockerfile\r│ └── HelloWorldApi.csproj\r├── frontend/\r│ ├── (Angular app here)\r│ └── Dockerfile\r└── docker-compose.yml\rStep 2: Backend - .NET 8 Web API Program.cs using Microsoft.EntityFrameworkCore; using Microsoft.Extensions.DependencyInjection; using HelloWorldApi.Data; var builder = WebApplication.CreateBuilder(args); builder.Services.AddControllers(); builder.Services.AddEndpointsApiExplorer(); builder.Services.AddSwaggerGen(); builder.Services.AddDbContext\u003cAppDbContext\u003e(options =\u003e options.UseNpgsql(builder.Configuration.GetConnectionString(\"DefaultConnection\"))); var app = builder.Build(); if (app.Environment.IsDevelopment()) { app.UseSwagger(); app.UseSwaggerUI(); } app.UseAuthorization(); app.MapControllers(); app.Run();\rData/AppDbContext.cs using Microsoft.EntityFrameworkCore; using HelloWorldApi.Models; namespace HelloWorldApi.Data { public class AppDbContext : DbContext { public AppDbContext(DbContextOptions\u003cAppDbContext\u003e options) : base(options) {} public DbSet\u003cMessage\u003e Messages { get; set; } } }\rModels/Message.cs namespace HelloWorldApi.Models { public class Message { public int Id { get; set; } public string Text { get; set; } } }\rControllers/MessageController.cs using Microsoft.AspNetCore.Mvc; using HelloWorldApi.Data; using HelloWorldApi.Models; using Microsoft.EntityFrameworkCore; using System.Threading.Tasks; using System.Collections.Generic; namespace HelloWorldApi.Controllers { [ApiController] [Route(\"api/[controller]\")] public class MessageController : ControllerBase { private readonly AppDbContext _context; public MessageController(AppDbContext context) { _context = context; } [HttpGet] public async Task\u003cIEnumerable\u003cMessage\u003e\u003e GetMessages() =\u003e await _context.Messages.ToListAsync(); [HttpPost] public async Task\u003cIActionResult\u003e CreateMessage(Message msg) { _context.Messages.Add(msg); await _context.SaveChangesAsync(); return CreatedAtAction(nameof(GetMessages), new { id = msg.Id }, msg); } } }\rappsettings.json { \"ConnectionStrings\": { \"DefaultConnection\": \"Host=postgres;Port=5432;Database=helloapi;Username=postgres;Password=postgres\" }, \"Logging\": { \"LogLevel\": { \"Default\": \"Information\", \"Microsoft.AspNetCore\": \"Warning\" } }, \"AllowedHosts\": \"*\" }\rDockerfile (backend) FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base WORKDIR /app EXPOSE 5000 FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build WORKDIR /src COPY . . RUN dotnet restore RUN dotnet publish -c Release -o /app/publish FROM base AS final WORKDIR /app COPY --from=build /app/publish . ENTRYPOINT [\"dotnet\", \"HelloWorldApi.dll\"]\rStep 3: Frontend - Angular App Generate Angular app:\nng new frontend --routing=false --style=css cd frontend ng generate component home\rsrc/app/app.component.html \u003ch2\u003eMessages\u003c/h2\u003e \u003cul\u003e \u003cli *ngFor=\"let message of messages\"\u003e{{ message.text }}\u003c/li\u003e \u003c/ul\u003e \u003cinput [(ngModel)]=\"newMessage\" /\u003e \u003cbutton (click)=\"addMessage()\"\u003eAdd\u003c/button\u003e\rsrc/app/app.component.ts import { HttpClient } from '@angular/common/http'; import { Component } from '@angular/core'; @Component({ selector: 'app-root', templateUrl: './app.component.html' }) export class AppComponent { messages: any[] = []; newMessage: string = ''; constructor(private http: HttpClient) { this.loadMessages(); } loadMessages() { this.http.get\u003cany[]\u003e('http://localhost:8080/api/message').subscribe(data =\u003e this.messages = data); } addMessage() { this.http.post('http://localhost:8080/api/message', { text: this.newMessage }).subscribe(() =\u003e { this.newMessage = ''; this.loadMessages(); }); } }\rDockerfile (frontend) FROM node:20-alpine AS build WORKDIR /app COPY . . RUN npm install \u0026\u0026 npm run build -- --output-path=dist FROM nginx:alpine COPY --from=build /app/dist /usr/share/nginx/html COPY nginx.conf /etc/nginx/nginx.conf\rnginx.conf server { listen 80; location / { root /usr/share/nginx/html; index index.html; try_files $uri $uri/ /index.html; } location /api/ { proxy_pass http://backend:5000/api/; } }\rStep 4: Docker Compose docker-compose.yml version: '3.9' services: frontend: build: ./frontend ports: - \"8080:80\" depends_on: - backend backend: build: ./backend environment: - ASPNETCORE_URLS=http://+:5000 ports: - \"5000:5000\" depends_on: - postgres postgres: image: postgres:15 restart: always environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: postgres POSTGRES_DB: helloapi volumes: - pgdata:/var/lib/postgresql/data volumes: pgdata:\rStep 5: Build \u0026 Run docker-compose up --build -d\rThen visit:\nAngular UI: http://localhost:8080 Swagger (API docs): http://localhost:5000/swagger",
    "description": "Step-by-step guide to build, containerize, and deploy a .NET Core Web API to a Kubernetes cluster using Docker.",
    "tags": [
      "Dotnet",
      "Kubernetes",
      "Docker",
      "Webapi",
      "Devops"
    ],
    "title": "Deploy a .NET Core Web API using Docker and Kubernetes",
    "uri": "/dotnet/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Introduction to Helm",
    "content": "🔍 Preview Manifests Before Installing To preview the rendered Kubernetes manifests from a Helm chart without installing it, use:\nhelm template \u003crelease-name\u003e \u003cchart-path-or-name\u003e\rExample: helm template my-nginx bitnami/nginx\r🧪 Simulate Installation (Dry Run) To simulate an install with all validations (including custom values):\nhelm install \u003crelease-name\u003e \u003cchart-path-or-name\u003e --dry-run --debug\rExample: helm install my-nginx bitnami/nginx --dry-run --debug\r📥 Get Values from Existing Release To retrieve the custom values used in an existing Helm release:\nhelm get values \u003crelease-name\u003e -n \u003cnamespace\u003e\rExample: helm get values my-nginx -n default\rTo get all values including defaults and overrides (merged output):\nhelm get values \u003crelease-name\u003e -n \u003cnamespace\u003e --all\rExample: helm get values my-nginx -n default --all\r📄 Get Default values.yaml from a Helm Chart To get the default values.yaml file from a Helm chart before installing it, use:\nhelm show values \u003cchart-name\u003e\r📦 Example (from a remote repository): helm show values bitnami/nginx\r📁 Example (from a local chart directory): helm show values ./mychart\rThis command prints all the default configuration options supported by the chart.\n💾 Save Default Values for Customization You can redirect the output to a file, edit it, and use it during installation:\nhelm show values bitnami/nginx \u003e custom-values.yaml\rThen install with:\nhelm install my-nginx bitnami/nginx --values custom-values.yaml\r✅ This is a best practice for controlled and repeatable deployments.\n🔧 Using -f, --values, and --set in Helm Helm allows customization of charts using:\n-f or --values to supply a YAML file with configuration overrides. --set to pass values inline via the command line. 📁 Using -f or --values (YAML file) helm install my-nginx bitnami/nginx -f custom-values.yaml\rhelm upgrade my-nginx bitnami/nginx -f dev-values.yaml -n dev\rYou can also supply multiple files in order of precedence:\nhelm install my-nginx bitnami/nginx -f base.yaml -f prod.yaml\rThe last file overrides values from the previous ones.\n💡 Using --set (Inline values) Set a single value inline:\nhelm install my-nginx bitnami/nginx --set service.type=LoadBalancer\rSet multiple values inline:\nhelm install my-nginx bitnami/nginx \\ --set replicaCount=2 \\ --set image.tag=1.23.0 \\ --set service.type=NodePort\r🔄 Combine --set and --values You can combine both options. Inline --set overrides the values in the file:\nhelm install my-nginx bitnami/nginx \\ -f custom-values.yaml \\ --set service.type=LoadBalancer\r📝 Set Nested/Array Values with --set For nested keys:\nhelm install my-nginx bitnami/nginx \\ --set metrics.enabled=true \\ --set ingress.enabled=true \\ --set ingress.hostname=nginx.example.com\r✅ Use --values for maintainable configurations,\n✅ Use --set for quick overrides or scripting.",
    "description": "🔍 Preview Manifests Before Installing To preview the rendered Kubernetes manifests from a Helm chart without installing it, use:\nhelm template \u003crelease-name\u003e \u003cchart-path-or-name\u003e\rExample: helm template my-nginx bitnami/nginx\r🧪 Simulate Installation (Dry Run) To simulate an install with all validations (including custom values):\nhelm install \u003crelease-name\u003e \u003cchart-path-or-name\u003e --dry-run --debug\rExample: helm install my-nginx bitnami/nginx --dry-run --debug\r📥 Get Values from Existing Release To retrieve the custom values used in an existing Helm release:",
    "tags": [],
    "title": "Additional",
    "uri": "/helm/additional/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Angular",
    "uri": "/tags/angular/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Clean Architecture",
    "uri": "/tags/clean-architecture/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Devops",
    "uri": "/tags/devops/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Dotnet",
    "uri": "/tags/dotnet/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Full-Stack",
    "uri": "/tags/full-stack/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Table of Contents Overview: What is Helm? Official Helm Documentation Working with Existing Helm Charts Adding and Managing Repositories Installing a Helm Release Using and Customizing values.yaml Overriding Values with --set Upgrading an Existing Release Rolling Back to a Previous Release Viewing Current Values of a Release Managing Multiple Environments Debugging and Dry Runs Creating Helm Charts Quick Start Guide Template Syntax \u0026 Structure Built-in Template Objects Overview: What is Helm? Helm is the package manager for Kubernetes. It enables developers and operators to package, configure, deploy, and manage applications on Kubernetes clusters using Helm charts—predefined templates that streamline complex deployments.\nPrerequisites Before you begin, ensure you have:\nA basic understanding of Kubernetes concepts Familiarity with Linux command-line operations Required Tools To follow along and perform hands-on tasks, you’ll need:\nVisual Studio Code (VSCode) or any preferred text editor The kubectl CLI to interact with Kubernetes The Helm CLI (helm) installed and configured Hands-On Labs This guide includes practical labs where you’ll learn how to:\nDeploy applications using publicly available Helm charts Customize deployments by editing chart values Create and deploy your own Helm charts Use Helm’s core features such as install, upgrade, rollback, and templating",
    "description": "Table of Contents Overview: What is Helm? Official Helm Documentation Working with Existing Helm Charts Adding and Managing Repositories Installing a Helm Release Using and Customizing values.yaml Overriding Values with --set Upgrading an Existing Release Rolling Back to a Previous Release Viewing Current Values of a Release Managing Multiple Environments Debugging and Dry Runs Creating Helm Charts Quick Start Guide Template Syntax \u0026 Structure Built-in Template Objects Overview: What is Helm? Helm is the package manager for Kubernetes. It enables developers and operators to package, configure, deploy, and manage applications on Kubernetes clusters using Helm charts—predefined templates that streamline complex deployments.",
    "tags": [],
    "title": "Introduction to Helm",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Postgresql",
    "uri": "/tags/postgresql/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Starter-Kit",
    "uri": "/tags/starter-kit/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Ci-Cd",
    "uri": "/tags/ci-cd/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Containers",
    "uri": "/tags/containers/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Docker",
    "uri": "/tags/docker/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Docker-Compose",
    "uri": "/tags/docker-compose/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Dockerfile",
    "uri": "/tags/dockerfile/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Jenkins",
    "uri": "/tags/jenkins/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Pipeline",
    "uri": "/tags/pipeline/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Tutorial",
    "uri": "/tags/tutorial/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Deploy a .NET Core Web API using Docker and Kubernetes",
    "content": "Overview This guide explains how to containerize and deploy the Learning Portal application (https://github.com/Ashish-Ranjan001/Learning-Portal-) using Docker and Kubernetes. The application is composed of:\nFrontend: Angular Backend: .NET Core Database: PostgreSQL Prerequisites Docker installed Kubernetes cluster (e.g., Minikube, CRC, K3s, or cloud-managed) kubectl configured Docker Hub account (e.g., nippy) Step 1: Clone the Repository git clone https://github.com/Ashish-Ranjan001/Learning-Portal-.git cd Learning-Portal-\rStep 2: Prepare the Directory Structure Learning-Portal-/ ├── frontend/ # Angular ├── backend/ # .NET Core ├── docker-compose.yml\rStep 3: Dockerize the Backend (.NET Core) Create backend/Dockerfile:\nFROM mcr.microsoft.com/dotnet/sdk:6.0 AS build WORKDIR /src COPY . . RUN dotnet restore RUN dotnet publish -c Release -o /app/publish FROM mcr.microsoft.com/dotnet/aspnet:6.0 WORKDIR /app COPY --from=build /app/publish . ENTRYPOINT [\"dotnet\", \"LearningPortal.dll\"]\rStep 4: Dockerize the Frontend (Angular) Create frontend/Dockerfile:\nFROM node:18-alpine as build WORKDIR /app COPY . . RUN npm install \u0026\u0026 npm run build --prod FROM nginx:alpine COPY --from=build /app/dist/* /usr/share/nginx/html\rStep 5: Create docker-compose.yml version: '3.8' services: db: image: postgres:15 environment: POSTGRES_USER: user POSTGRES_PASSWORD: password POSTGRES_DB: learning volumes: - pgdata:/var/lib/postgresql/data networks: - appnet backend: build: ./backend depends_on: - db environment: - DB_HOST=db - DB_USER=user - DB_PASS=password - DB_NAME=learning networks: - appnet frontend: build: ./frontend ports: - \"80:80\" depends_on: - backend networks: - appnet volumes: pgdata: networks: appnet:\rStep 6: Build and Push Docker Images # Backend cd backend docker build -t nippy/learning-backend:latest . docker push nippy/learning-backend:latest # Frontend cd ../frontend docker build -t nippy/learning-frontend:latest . docker push nippy/learning-frontend:latest",
    "description": "Step-by-step guide to containerize and deploy a .NET Core + Angular + PostgreSQL application using Docker and Kubernetes",
    "tags": [],
    "title": "Deploying Learning Portal with Docker and Kubernetes",
    "uri": "/dotnet/session02/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Kubernetes",
    "uri": "/tags/kubernetes/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Webapi",
    "uri": "/tags/webapi/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e Deploy a .NET Core Web API using Docker and Kubernetes",
    "content": "Install ms sql on container docker run -e \"ACCEPT_EULA=Y\" \\ -e \"MSSQL_SA_PASSWORD=Redhat@123456\" \\ -p 1433:1433 \\ --name sql2022 \\ -d mcr.microsoft.com/mssql/server:2022-latest\rCreate a database in Ms sql docker run -it --rm \\ --network container:sql2022 \\ mcr.microsoft.com/mssql-tools \\ /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P 'Redhat@123456' -Q \"CREATE DATABASE LMSDatabase\"\rCheck the database if available docker run -it --rm --network container:sql2022 mcr.microsoft.com/mssql-tools /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P 'Redhat@123456' 1\u003e SELECT name FROM sys.databases; 2\u003e GO name -------------------------------------------------------------------------------------------------------------------------------- master tempdb model msdb LMSDatabase (5 rows affected)\r{ \"ConnectionStrings\": { \"DefaultConnection\": \"Server=localhost,1433;Database=LMSDatabase;User Id=sa;Password=Redhat@123456;TrustServerCertificate=true\" } }\r🚀 Host a Static Website with IIS in Docker (Windows) This guide walks you through creating and deploying a simple static HTML site using IIS inside a Docker container on Windows.\n📁 Project Structure iis-static-site/\r├── Dockerfile\r└── html/\r└── index.html\r📝 Step 1: Create index.html html/index.html\n\u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eWelcome to IIS Container\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eHello from Docker + IIS!\u003c/h1\u003e \u003cp\u003eThis static page is served from an IIS container.\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e\r🐳 Step 2: Create Dockerfile Dockerfile\n# Use the official IIS image FROM mcr.microsoft.com/windows/servercore/iis # Copy static site contents to IIS web root COPY ./html/ /inetpub/wwwroot/\r🏗️ Step 3: Build Docker Image Open PowerShell or Command Prompt in the project root and run:\ndocker build -t iis-static-site .\r▶️ Step 4: Run the Container docker run -d -p 8080:80 --name iis-container iis-static-site\r🌐 Step 5: Access the Website Visit the following URL in your browser:\nhttp://localhost:8080\rYou should see:\n✅ Hello from Docker + IIS!\n🧹 Step 6: Stop \u0026 Remove Container (Optional) docker stop iis-container docker rm iis-container\rhttps://learn.microsoft.com/en-us/dotnet/core/docker/build-container?tabs=linux\u0026pivots=dotnet-8-0 Some Example: https://github.com/nitin27may/clean-architecture-docker-dotnet-angular https://github.com/trevoirwilliams/ConferenceAttendees.CloudNativeDevelopment.git https://learn.microsoft.com/en-us/visualstudio/containers/tutorial-multicontainer?view=vs-2022\nhttps://ravindradevrani.medium.com/containerize-your-net-application-with-sql-server-using-docker-compose-d04b0c4ff4d1\nhttps://github.com/docker/awesome-compose/tree/master/aspnet-mssql",
    "description": "Install ms sql on container docker run -e \"ACCEPT_EULA=Y\" \\ -e \"MSSQL_SA_PASSWORD=Redhat@123456\" \\ -p 1433:1433 \\ --name sql2022 \\ -d mcr.microsoft.com/mssql/server:2022-latest\rCreate a database in Ms sql docker run -it --rm \\ --network container:sql2022 \\ mcr.microsoft.com/mssql-tools \\ /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P 'Redhat@123456' -Q \"CREATE DATABASE LMSDatabase\"\rCheck the database if available docker run -it --rm --network container:sql2022 mcr.microsoft.com/mssql-tools /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P 'Redhat@123456' 1\u003e SELECT name FROM sys.databases; 2\u003e GO name -------------------------------------------------------------------------------------------------------------------------------- master tempdb model msdb LMSDatabase (5 rows affected)\r{ \"ConnectionStrings\": { \"DefaultConnection\": \"Server=localhost,1433;Database=LMSDatabase;User Id=sa;Password=Redhat@123456;TrustServerCertificate=true\" } }\r🚀 Host a Static Website with IIS in Docker (Windows) This guide walks you through creating and deploying a simple static HTML site using IIS inside a Docker container on Windows.",
    "tags": [
      "Docker",
      "Dockerfile",
      "Containers",
      "Devops",
      "Tutorial"
    ],
    "title": ".NET Related containers",
    "uri": "/dotnet/misc/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e GIT Version Control System",
    "content": "🚀 Git Tutorial from Start — With Real-Time Examples 📘 Table of Contents 🚀 Git Tutorial from Start — With Real-Time Examples 📘 Table of Contents 📌 What is Git? 🧰 Installing Git For Linux: For macOS: For Windows: ⚙️ Git Configuration 🔄 Basic Git Workflow 🧬 Cloning a Repository ✍️ Making Changes \u0026 Committing 🌿 Branching and Merging 🔄 Real-Time Example: Feature Branch Workflow 📦 Stashing Changes 🌐 Working with Remotes 📜 Git Log and History 🔙 Undoing Things 🚫 .gitignore File 🏷️ Git Tags ✅ Conclusion 📌 What is Git? Git is a distributed version control system. Tracks changes in source code during software development. Helps teams collaborate on code. 🧰 Installing Git For Linux: sudo apt update sudo apt install git\rFor macOS: brew install git\rFor Windows: Download from: https://git-scm.com/downloads ⚙️ Git Configuration git config --global user.name \"Your Name\" git config --global user.email \"you@example.com\" git config --list # verify settings\r🔄 Basic Git Workflow git init # Initialize a Git repository git status # Check current status git add file.txt # Stage a file git commit -m \"Added file\" # Commit with message\r🧬 Cloning a Repository git clone https://github.com/yourusername/project.git\r✍️ Making Changes \u0026 Committing echo \"Hello Git\" \u003e hello.txt git add hello.txt git commit -m \"Added hello.txt file\"\r🌿 Branching and Merging git branch # List branches git branch feature-x # Create a new branch git checkout feature-x # Switch to branch # Make changes and commit git checkout main git merge feature-x # Merge branch into main\r🔄 Real-Time Example: Feature Branch Workflow Scenario: You are adding a login feature.\ngit checkout -b feature/login # Add login logic to login.js git add login.js git commit -m \"Add login feature\" git push origin feature/login # Open a Merge Request (MR) on GitLab/GitHub\rAfter MR approval:\ngit checkout main git pull origin main git merge feature/login git push origin main\r📦 Stashing Changes git stash # Save uncommitted changes git pull origin main git stash pop # Apply stashed changes\r🌐 Working with Remotes git remote -v # Show configured remotes git remote add origin \u003crepo-url\u003e # Add remote repository git push -u origin main # Push code to remote git pull origin main # Pull latest changes\r📜 Git Log and History git log # View commit logs git log --oneline --graph --all # Pretty graph format\r🔙 Undoing Things git checkout -- file.txt # Discard uncommitted changes git reset HEAD~1 # Undo last commit (keep changes) git revert \u003ccommit-id\u003e # Revert a specific commit\r🚫 .gitignore File Create a .gitignore file in the project root to ignore files/folders.\n# .gitignore example *.log node_modules/ .env .idea/ .DS_Store\r🏷️ Git Tags git tag v1.0 # Lightweight tag git tag -a v1.1 -m \"Release v1.1\" # Annotated tag git push origin --tags # Push tags to remote\r✅ Conclusion Git is essential for modern development workflows. Use branches and MRs for cleaner collaboration. Practice using add, commit, push, and pull regularly. Use git status and git log to understand project state. 🙌 Happy Coding with Git! Keep committing and stay versioned!",
    "description": "🚀 Git Tutorial from Start — With Real-Time Examples 📘 Table of Contents 🚀 Git Tutorial from Start — With Real-Time Examples 📘 Table of Contents 📌 What is Git? 🧰 Installing Git For Linux: For macOS: For Windows: ⚙️ Git Configuration 🔄 Basic Git Workflow 🧬 Cloning a Repository ✍️ Making Changes \u0026 Committing 🌿 Branching and Merging 🔄 Real-Time Example: Feature Branch Workflow 📦 Stashing Changes 🌐 Working with Remotes 📜 Git Log and History 🔙 Undoing Things 🚫 .gitignore File 🏷️ Git Tags ✅ Conclusion 📌 What is Git? Git is a distributed version control system. Tracks changes in source code during software development. Helps teams collaborate on code. 🧰 Installing Git For Linux: sudo apt update sudo apt install git\rFor macOS: brew install git\rFor Windows: Download from: https://git-scm.com/downloads ⚙️ Git Configuration git config --global user.name \"Your Name\" git config --global user.email \"you@example.com\" git config --list # verify settings\r🔄 Basic Git Workflow git init # Initialize a Git repository git status # Check current status git add file.txt # Stage a file git commit -m \"Added file\" # Commit with message\r🧬 Cloning a Repository git clone https://github.com/yourusername/project.git\r✍️ Making Changes \u0026 Committing echo \"Hello Git\" \u003e hello.txt git add hello.txt git commit -m \"Added hello.txt file\"\r🌿 Branching and Merging git branch # List branches git branch feature-x # Create a new branch git checkout feature-x # Switch to branch # Make changes and commit git checkout main git merge feature-x # Merge branch into main\r🔄 Real-Time Example: Feature Branch Workflow Scenario: You are adding a login feature.",
    "tags": [],
    "title": "Git",
    "uri": "/git/git01/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e GIT Version Control System",
    "content": "🔍 Advanced git log Examples git log is highly customizable. Here are real-world examples:\n📦 Basic Commit Log git log\rShows full commit history with author, date, and message.\n🧵 One-line Log (Condensed View) git log --oneline\rShows each commit as a single line: useful for quick scanning.\n🌲 Visual Branch Graph git log --oneline --graph --all\rDisplays commit history as a branch graph across all branches.\n📆 Log with Dates git log --pretty=format:\"%h - %an, %ar : %s\"\rCustom format: shows commit hash, author, relative date, and message.\n🔎 Filter by Author git log --author=\"nirpendra\"\rShows only commits made by a specific author.\n🕐 Commits from the Last 7 Days git log --since=\"7 days ago\"\rOr filter between two dates:\ngit log --since=\"2024-06-01\" --until=\"2024-06-30\"\r📁 Log for a Specific File git log -- \u003cfile-path\u003e\rView changes made to a particular file.\nExample:\ngit log -- src/main.py\r🧾 Show Diff with Each Commit git log -p\rIncludes the patch (code changes) with each commit.\n🧰 Combined Format: Pretty + Graph + Oneline git log --pretty=format:\"%C(yellow)%h%Creset %Cgreen%ad%Creset %C(cyan)%an%Creset - %s\" --date=short --graph\rThis gives a colorful, structured view:\nHash in yellow Date in green Author in cyan 🔢 Limit the Number of Commits git log -n 5\rShows the last 5 commits only.\n📊 Stats Per Commit git log --stat\rDisplays each commit along with the number of lines added/removed and the file names.\n📜 List Files Modified in Last Commit git log -1 --name-only\r🔐 View Only Merge Commits git log --merges\r💡 Tip: You can combine these flags for powerful custom outputs! Example:\ngit log --oneline --author=\"nirpendra\" --since=\"1 week ago\"",
    "description": "🔍 Advanced git log Examples git log is highly customizable. Here are real-world examples:\n📦 Basic Commit Log git log\rShows full commit history with author, date, and message.\n🧵 One-line Log (Condensed View) git log --oneline\rShows each commit as a single line: useful for quick scanning.\n🌲 Visual Branch Graph git log --oneline --graph --all\rDisplays commit history as a branch graph across all branches.",
    "tags": [],
    "title": "Git Logs",
    "uri": "/git/git02/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e GIT Version Control System",
    "content": "📜 Git Log and History git log git log --oneline git log --oneline --graph --all\r🔙 Undoing Things git checkout -- file git revert \u003ccommit\u003e\r🧠 Understanding git reset git reset --soft HEAD~1 # Keep changes staged git reset --mixed HEAD~1 # Keep changes, unstage git reset --hard HEAD~1 # Discard changes\r🔍 Advanced git log Examples git log # Full history git log --oneline # Short view git log --graph --oneline # Tree view git log --author=\"name\" git log --since=\"7 days ago\" git log -p # Show diffs git log --stat # File changes git log -1 --name-only # Files in last commit git log --merges # Only merge commits\r🚫 .gitignore File *.log\r.env\rnode_modules/\r.idea/\r🏷️ Git Tags git tag v1.0 git tag -a v1.1 -m \"Release v1.1\" git push origin --tags\r✅ Conclusion Use Git daily. Learn branching, logs, reset, and collaboration with remotes. Practice makes perfect!\n🙌 Happy Coding with Git!",
    "description": "📜 Git Log and History git log git log --oneline git log --oneline --graph --all\r🔙 Undoing Things git checkout -- file git revert \u003ccommit\u003e\r🧠 Understanding git reset git reset --soft HEAD~1 # Keep changes staged git reset --mixed HEAD~1 # Keep changes, unstage git reset --hard HEAD~1 # Discard changes\r🔍 Advanced git log Examples git log # Full history git log --oneline # Short view git log --graph --oneline # Tree view git log --author=\"name\" git log --since=\"7 days ago\" git log -p # Show diffs git log --stat # File changes git log -1 --name-only # Files in last commit git log --merges # Only merge commits\r🚫 .gitignore File *.log\r.env\rnode_modules/\r.idea/\r🏷️ Git Tags git tag v1.0 git tag -a v1.1 -m \"Release v1.1\" git push origin --tags\r✅ Conclusion Use Git daily. Learn branching, logs, reset, and collaboration with remotes. Practice makes perfect!",
    "tags": [],
    "title": "Git More Examples ",
    "uri": "/git/git_tutorial/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm \u003e GIT Version Control System",
    "content": "🧩 Git Merge Methods Explained 🔸 1. Fast-Forward Merge 📌 What: Moves the branch pointer forward because there’s no divergent history.\n🧪 Example: git checkout main git merge feature-branch\r✅ If main is behind feature-branch but has no new commits, Git just moves main forward — no merge commit is created.\n📊 Result: No extra commit. Clean history. Only possible when histories are linear (no parallel commits). 🔸 2. Three-Way Merge (Default) 📌 What: Used when branches diverged — Git creates a merge commit.\n🧪 Example: git checkout main git merge feature-branch\r🔄 If both main and feature-branch have new commits, Git creates a merge commit to tie them.\n📊 Result: Merge commit created. Retains full history of both branches. Good for preserving commit context. 🔸 3. Squash Merge 📌 What: Combines all commits from the feature branch into a single commit on the target branch.\n🧪 Example: git checkout main git merge --squash feature-branch git commit -m \"Add feature X\"\r📝 All feature-branch commits are flattened into one.\n📊 Result: Clean, single commit. Good for simplifying history. Loses detailed history of feature-branch. 🔸 4. Rebase + Fast-Forward 📌 What: Rewrites feature branch history onto base branch — keeps history linear and avoids merge commits.\n🧪 Example: git checkout feature-branch git rebase main git checkout main git merge --ff-only feature-branch\r📈 Keeps history tidy and linear.\n📊 Result: No merge commits. Linear history. Can be risky if rebasing shared branches (changes commit hashes). 🔸 5. No-Fast-Forward Merge (--no-ff) 📌 What: Forces Git to always create a merge commit, even if a fast-forward is possible.\n🧪 Example: git merge --no-ff feature-branch\r🔗 Use this to clearly show a branch was merged, even if no divergence.\n📊 Result: Always a merge commit. Good for clear separation of features in history. 🔍 Summary Table Merge Method Merge Commit History Type Use Case Fast-Forward ❌ No Linear Simple updates Three-Way Merge ✅ Yes Diverged Default for complex merges Squash Merge ❌ One commit Simplified Clean history, single logical change Rebase + FF ❌ No Linear Clean history before merge No-FF ✅ Yes Always visible Always document a merge explicitly 🧠 Best Practices ✅ Use squash for feature branches in solo/team projects to simplify history. ✅ Use no-ff in protected/main branches for clear audit trails. ✅ Use rebase to clean up local commits before merging. 🔁 Understanding git rebase 🔹 What is git rebase? git rebase is used to move or combine a sequence of commits to a new base commit. It is often used to maintain a cleaner, linear project history.\nUnlike merge, which creates a new commit, rebase re-applies commits on top of another branch.\n🔹 Syntax git rebase \u003cupstream-branch\u003e\rExample:\ngit checkout feature git rebase main\rThis reapplies your feature branch commits on top of the latest main.\n🔹 Common Use Case: Updating Feature Branch # Assume you're on feature branch git checkout feature/login git fetch origin git rebase origin/main\r✅ This puts your feature branch on top of the latest main, as if it was created from it.\n🔹 Resolving Conflicts During Rebase If conflicts occur:\n# After editing the file to fix conflicts git add \u003cresolved-file\u003e git rebase --continue\rTo skip the current commit:\ngit rebase --skip\rTo abort the rebase and return to the previous state:\ngit rebase --abort\r🔄 Interactive Rebase Use this to edit, squash, or reword commits.\ngit rebase -i HEAD~3\rExample interactive menu:\npick 3f5e1f9 Added login form\rpick 89d2ac3 Fixed typo in login\rsquash d14e7a3 Updated form styles\rChange pick to:\nreword — change the commit message squash — combine commits into one edit — pause to change code during rebase 🆚 Rebase vs Merge Feature git merge git rebase History Keeps history with a merge commit Creates a linear history Commit Graph May look like a tree Looks like a straight line Use When You want to preserve all changes You want a clean history 🚫 Don’t Rebase Shared Branches ⚠️ Avoid using git rebase on branches that others are working on (i.e., already pushed/shared), unless you coordinate with your team.\n🔧 Example: Clean Up Before Merge Request git checkout feature/payment git rebase -i HEAD~5 # squash into a single commit\rThen:\ngit push -f origin feature/payment\r💡 Tip: Use git log --oneline --graph before and after rebase to visualize the change.",
    "description": "🧩 Git Merge Methods Explained 🔸 1. Fast-Forward Merge 📌 What: Moves the branch pointer forward because there’s no divergent history.\n🧪 Example: git checkout main git merge feature-branch\r✅ If main is behind feature-branch but has no new commits, Git just moves main forward — no merge commit is created.\n📊 Result: No extra commit. Clean history. Only possible when histories are linear (no parallel commits). 🔸 2. Three-Way Merge (Default) 📌 What: Used when branches diverged — Git creates a merge commit.",
    "tags": [],
    "title": "Git Rebase and Merge",
    "uri": "/git/git04/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm",
    "content": "🧾 What is Git? Git is a free, open-source, and distributed version control system designed to handle everything from small to very large projects with speed and efficiency.\n🔧 In Simple Terms Git helps track changes in your code (or any files), collaborate with others, and go back in time to previous versions.\n🧠 Key Features of Git Feature Description ✅ Distributed Every developer has a full copy of the repository. ⏳ Version Tracking Keeps a history of every change (who, what, when, and why). 🧪 Branching \u0026 Merging Create isolated environments (branches), and combine them when ready. ⚡ Fast \u0026 Efficient Designed to be fast — especially for large projects. 🔐 Secure Uses checksums (SHA-1) to ensure data integrity. 📦 Git vs GitHub Git GitHub Version control tool (CLI) Web-based platform for Git repositories Works locally Requires internet/browser for collaboration Can be used independently Built on top of Git 📂 Real-World Analogy Imagine writing a book:\nGit keeps snapshots of your book at every stage. You can always go back to Chapter 1 or see who edited Chapter 3. You can write Chapter 4 separately (branch), and merge it when done. 💻 Common Git Commands Command Purpose git init Initialize a new Git repo git clone \u003curl\u003e Copy a remote repo git status Check file status git add \u003cfile\u003e Stage changes git commit -m \"message\" Save snapshot git push Upload changes to remote git pull Fetch and merge changes from remote git branch List branches git checkout -b \u003cbranch\u003e Create and switch to a new branch git merge \u003cbranch\u003e Merge another branch into current one 🧑‍🤝‍🧑 Who Uses Git? Developers DevOps Engineers System Admins Writers Data Scientists Basically, anyone who works with files that change over time.",
    "description": "🧾 What is Git? Git is a free, open-source, and distributed version control system designed to handle everything from small to very large projects with speed and efficiency.\n🔧 In Simple Terms Git helps track changes in your code (or any files), collaborate with others, and go back in time to previous versions.\n🧠 Key Features of Git Feature Description ✅ Distributed Every developer has a full copy of the repository. ⏳ Version Tracking Keeps a history of every change (who, what, when, and why). 🧪 Branching \u0026 Merging Create isolated environments (branches), and combine them when ready. ⚡ Fast \u0026 Efficient Designed to be fast — especially for large projects. 🔐 Secure Uses checksums (SHA-1) to ensure data integrity. 📦 Git vs GitHub Git GitHub Version control tool (CLI) Web-based platform for Git repositories Works locally Requires internet/browser for collaboration Can be used independently Built on top of Git 📂 Real-World Analogy Imagine writing a book:",
    "tags": [],
    "title": "GIT Version Control System",
    "uri": "/git/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm",
    "content": "Table of Contents Overview: What is Helm? Official Helm Documentation Working with Existing Helm Charts Adding and Managing Repositories Installing a Helm Release Using and Customizing values.yaml Overriding Values with --set Upgrading an Existing Release Rolling Back to a Previous Release Viewing Current Values of a Release Managing Multiple Environments Debugging and Dry Runs Creating Helm Charts Quick Start Guide Template Syntax \u0026 Structure Built-in Template Objects Overview: What is Helm? Helm is the package manager for Kubernetes. It enables developers and operators to package, configure, deploy, and manage applications on Kubernetes clusters using Helm charts—predefined templates that streamline complex deployments.\nPrerequisites Before you begin, ensure you have:\nA basic understanding of Kubernetes concepts Familiarity with Linux command-line operations Required Tools To follow along and perform hands-on tasks, you’ll need:\nVisual Studio Code (VSCode) or any preferred text editor The kubectl CLI to interact with Kubernetes The Helm CLI (helm) installed and configured Hands-On Labs This guide includes practical labs where you’ll learn how to:\nDeploy applications using publicly available Helm charts Customize deployments by editing chart values Create and deploy your own Helm charts Use Helm’s core features such as install, upgrade, rollback, and templating",
    "description": "Table of Contents Overview: What is Helm? Official Helm Documentation Working with Existing Helm Charts Adding and Managing Repositories Installing a Helm Release Using and Customizing values.yaml Overriding Values with --set Upgrading an Existing Release Rolling Back to a Previous Release Viewing Current Values of a Release Managing Multiple Environments Debugging and Dry Runs Creating Helm Charts Quick Start Guide Template Syntax \u0026 Structure Built-in Template Objects Overview: What is Helm? Helm is the package manager for Kubernetes. It enables developers and operators to package, configure, deploy, and manage applications on Kubernetes clusters using Helm charts—predefined templates that streamline complex deployments.",
    "tags": [],
    "title": "Introduction to Helm",
    "uri": "/helm/index.html"
  },
  {
    "breadcrumb": "Introduction to Helm",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Vmware Vsphere",
    "uri": "/vmware/index.html"
  }
]
